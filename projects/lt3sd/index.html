<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>LT3SD: Latent Trees for 3D Scene Diffusion</title>
    <meta name="author" content="Quan Meng" />
    <meta name="description" content="LT3SD: Latent Trees for 3D Scene Diffusion" />
    <meta name="keywords" content="3D Scene Generation, Diffusion Model" />
    
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,500,700|Roboto+Slab:400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />
    <link rel="shortcut icon" href="/assets/img/favicon.ico"/>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://quan-meng.github.io/projects/lt3sd">
    
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    
    <style>
      .embed-responsive-3by1 {
        padding-top: 35%;
      }
      .content-block {
            width: 80%;            /* Set width as a percentage of the container */
            max-width: 800px;       /* Set a maximum width */
            margin: 0 auto;         /* Center the text horizontally */
        }
    </style>
</head>

<body class="sticky-bottom-footer">
    <div class="container mt-5">
        <div class="post">
            <h1 class="post-title text-center">LT3SD: Latent Trees for 3D Scene Diffusion</h1>
            <div class="d-flex justify-content-center">
                <ul class="list-inline">
                    <li class="list-inline-item px-3 pt-3">
                        <h4><a href="https://quan-meng.github.io" target="_blank" rel="noopener noreferrer">Quan Meng</a></h4>
                    </li>
                    <li class="list-inline-item px-3 pt-3">
                        <h4><a href="https://craigleili.github.io" target="_blank" rel="noopener noreferrer">Lei Li</a></h4>
                    </li>
                    <li class="list-inline-item px-3 pt-3">
                        <h4><a href="https://www.niessnerlab.org" target="_blank" rel="noopener noreferrer">Matthias Nie√üner</a></h4>
                    </li>
                    <li class="list-inline-item px-3 pt-3">
                        <h4><a href="https://www.3dunderstanding.org/team.html" target="_blank" rel="noopener noreferrer">Angela Dai</a></h4>
                    </li>
                </ul>
            </div>
            <div class="d-flex justify-content-center">
                <ul class="list-inline">
                    <li class="list-inline-item">
                        <h5>Technical University of Munich</h5>
                    </li>
                </ul>
            </div>
            
            <div class="d-flex justify-content-center">
                <ul class="list-inline">
                    <li class="list-inline-item">
                        <a href="http://arxiv.org/pdf/2409.08215" target="_blank" rel="noopener noreferrer">
                            <span class="btn btn-outline-dark btn-sm waves-effect waves-light"><i class="fas fa-file-pdf"></i> Paper</span>
                        </a>
                    </li>
                    <li class="list-inline-item">
                        <a href="https://youtu.be/AJ5sG9VyjGA" target="_blank" rel="noopener noreferrer">
                            <span class="btn btn-outline-dark btn-sm waves-effect waves-light"><i class="fab fa-youtube"></i> Video</span>
                        </a>
                    </li>
                    <li class="list-inline-item">
                        <a href="https://github.com/quan-meng/lt3sd" target="_blank" rel="noopener noreferrer">
                            <span class="btn btn-outline-dark btn-sm waves-effect waves-light"><i class="fab fa-github"></i> Code</span>
                        </a>
                    </li>
                </ul>
            </div>

            <div class="embed-responsive embed-responsive-16by9">
                <video class="embed-responsive-item" muted autoplay loop>
                    <source src="../../assets/lt3sd/fly_video.mp4" type="video/mp4" />
                </video>
            </div>

            <h2 class="text-center">Abstract</h2>

            <p class="content-block">
            We present <strong>LT3SD</strong>, a novel latent diffusion model for large-scale 3D scene generation.
            Recent advances in diffusion models have shown impressive results in 3D object generation,
            but they are limited to the object level and do not scale well to more complex 3D scenes.
                
            To generate complex, diverse 3D scene structures, we introduce a latent tree representation to effectively encode both lower-frequency geometry and
            higher-frequency detail in a coarse-to-fine hierarchy. We can then learn a generative diffusion process in this latent 3D scene space, 
            modeling the latent components of a scene at each resolution level. To synthesize large-scale scenes with varying sizes, 
            we train our diffusion model on scene patches and synthesize arbitrary-sized output 3D scenes through shared diffusion generation across multiple scene patches.
                
            Through extensive experiments, we demonstrate the efficacy and benefits of <strong>LT3SD</strong> for large-scale, high-quality unconditional 3D scene generation 
            and for probabilistic completion for partial scene observations.</p>

            <div class="embed-responsive embed-responsive-16by9">
                <video class="embed-responsive-item" muted autoplay loop>
                    <source src="../../assets/lt3sd/intermediate_video.mp4" type="video/mp4" />
                </video>
            </div>
            <p class="content-block">
                <strong>LT3SD</strong> enables high-fidelity generation of infinite 3D environments in a patch-by-patch and coarse-to-fine fashion.
                A sample of infinite 3D scene mesh can be downloaded <a href="https://tumde-my.sharepoint.com/:u:/g/personal/quan_meng_tum_de/EdCzaK1U9gBAvV_ta_BLQRABqqzthb6a1ZHLrWOkf1zmMw?e=45idDs" target="_blank" rel="noopener noreferrer">here</a>.
            </p>
                
            <h2 class="text-center pt-3">Video</h2>
            <div class="container content-block">
                <div class="embed-responsive embed-responsive-16by9">
                    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/AJ5sG9VyjGA?si=aeYxajefHDz8PKwO" allowfullscreen=""></iframe>
                </div>
            </div>

            <h2 class="text-center pt-5">How It Works</h2>
            <div class='content-block'>
                <div class="row">
                    <div class="col-sm mt-3 mt-md-0">
                        <figure>
                            <picture>
                                <img class="img-fluid rounded z-depth-1" src="../../assets/lt3sd/pipeline.png" title="Method">
                            </picture>
                        </figure>
                    </div>
                </div>
            </div>

            <p class="content-block">
                We present <span style="font-weight: bold;">LT3SD</span>, a novel latent diffusion model for large-scale 3D scene generation. 
                
                Recent advances in diffusion models have shown impressive results in 3D object generation, but are limited in spatial extent and quality when extended to 3D scenes. 
                To generate complex and diverse 3D scene structures, we introduce a latent tree representation to effectively encode both lower-frequency geometry and higher-frequency 
                detail in a coarse-to-fine hierarchy. We can then learn a generative diffusion process in this latent 3D scene space, modeling the latent components of a scene at each 
                resolution level. 
                
                To synthesize large-scale scenes with varying sizes, we train our diffusion model on scene patches and synthesize arbitrary-sized output 3D scenes 
                through shared diffusion generation across multiple scene patches. Through extensive experiments, we demonstrate the efficacy and benefits of <span style="font-weight: bold;">LT3SD</span> for large-scale, 
                high-quality unconditional 3D scene generation and for probabilistic completion for partial scene observations.
            </p>

            <h2 class="text-center pt-3">Comparisons</h2>
            <div class="content-block">
                <img class="img-fluid rounded z-depth-1" src="../../assets/lt3sd/comparison.png" title="Comparisons">
            </div>

            <p class="content-block">
                We compare unconditional 3D scene generation with diverse 3D diffusion methods PVD, NFD, and BlockFusion. 
                All methods were trained on the house level of the 3D-FRONT dataset. Our latent tree-based 3D scene diffusion approach synthesizes cleaner surfaces with 
                more geometric details and captures diverse furniture objects.
            </p>

            <h2 class="text-center pt-3">Citation</h2>
            <div class="content-block">
                <div class="bibtex">
                    <figure class="highlight">
                        <pre><code class="language-bibtex" data-lang="bibtex">
@misc{meng2024lt3sdlatenttrees3d,
    title={LT3SD: Latent Trees for 3D Scene Diffusion}, 
    author={Quan Meng and Lei Li and Matthias Nie√üner and Angela Dai},
    journal={arXiv preprint arXiv:2409.08215},
    year={2024}
}
                        </code></pre>
                    </figure>
                </div>
            </div>

            <h2 class="text-center pt-3">Acknowledgements</h2>
            <p class="content-block">
                This work was supported by the ERC Starting Grant SpatialSem (101076253). Matthias Niessner was supported by the ERC Starting Grant Scan2CAD (804724).
            </p>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
    <script defer src="/assets/js/masonry.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
    <script src="/assets/js/zoom.js"></script>
    <script src="/assets/js/common.js"></script>
    <script type="text/javascript">
        window.MathJax = {
            tex: {
                tags: 'ams'
            }
        };
    </script>
    <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-P3RT2Z6SLL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-P3RT2Z6SLL');
    </script>

</body>


</html>
